{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pamela09oliveira02-ctrl/SITE-DE-GERENCIADOR-DE-TEXTO/blob/main/Template_Gerenciador_de_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ti4uBMDNZXs"
      },
      "source": [
        "# Título do Projeto\n",
        "**Curso:GTI**\n",
        "**Turma:4NA**  \n",
        "**Integrantes do grupo: PAMELA CAMARGO, EDUARDO MARQUES, MATHEUS RAMALHO, DANILO SOUZA, FELIPE  DE PAULA**  \n",
        "**Data:23/11/2025**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introdução\n",
        "\n",
        "### 1.1 Contexto e motivação\n",
        ">  A geração de conteúdo textual criativo e de alta qualidade é uma necessidade crescente em diversos setores. O cenário atual é marcado pela demanda por ferramentas que possam auxiliar na superação do bloqueio criativo e na expansão rápida de ideias iniciais. O desenvolvimento de um Gerador de Texto Criativo com IA surge como uma solução para este desafio, aproveitando o avanço dos modelos de linguagem de grande escala (LLMs) para oferecer um assistente de escrita versátil e adaptável.\n",
        "\n",
        "\n",
        "### 1.2 Definição do problema\n",
        ">  A tarefa tratada neste trabalho é a Geração de Texto Condicional e Contínua. O problema consiste em receber uma entrada textual inicial (uma frase, um parágrafo ou uma ideia) e, com base nela, gerar uma saída que seja uma continuação coerente, estilisticamente adaptada e criativamente expandida do texto original. O projeto foca-se em demonstrar a capacidade de um LLM de adaptar seu estilo de resposta através de instruções de sistema (system instructions)..\n",
        "\n",
        "### 1.3 Objetivos e escopo\n",
        "> Objetivo Geral: Demonstrar a integração e o controle de um modelo de linguagem de grande escala (LLM) para a geração de texto criativo, utilizando a API Gemini.\n",
        "\n",
        "Objetivos Específicos:\n",
        "\n",
        "Integrar o ambiente de desenvolvimento com o modelo de linguagem gemini-2.5-flash via API.\n",
        "Implementar três modos de geração distintos (Criativo, Direto, Livre) através de instruções de sistema específicas.\n",
        "Demonstrar a influência dos hiperparâmetros de geração (como temperature) na saída do modelo.\n",
        "\n",
        "Escopo: O projeto foca-se na integração da API e na Engenharia de Prompt. Não está no escopo o treinamento ou o fine-tuning de um modelo de linguagem próprio, nem a análise exploratória de um dataset local.\n"
      ],
      "id": "6ti4uBMDNZXs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMmfBVFENZXx"
      },
      "source": [
        "## 2. Setup do Ambiente\n",
        "\n",
        "Nesta seção, faremos a importação das bibliotecas necessárias e a configuração inicial do ambiente.\n"
      ],
      "id": "cMmfBVFENZXx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL4F4_ZDNZXy"
      },
      "source": [
        "#@title Instalação (se necessário) { display-mode: \"form\" }\n",
        "\n",
        "# Adicione instalações específicas do projeto, se houver.\n",
        "# Exemplo:\n",
        "# !pip install -q transformers datasets gradio\n"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "TL4F4_ZDNZXy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9nbQZlJNZXz"
      },
      "source": [
        "#@title Importação de bibliotecas principais { display-mode: \"form\" }\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Bibliotecas de visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning clássico\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, confusion_matrix\n",
        ")\n",
        "\n",
        "# TODO: importe aqui as bibliotecas específicas do seu projeto\n",
        "# Exemplo:\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# import torch\n",
        "# import torch.nn as nn\n"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "Z9nbQZlJNZXz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e40HUq7PNZXz"
      },
      "source": [
        "#@title Configurações gerais { display-mode: \"form\" }\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 100)\n",
        "pd.set_option(\"display.max_rows\", 50)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Se estiver usando frameworks como torch ou tensorflow:\n",
        "# import torch\n",
        "# torch.manual_seed(RANDOM_STATE)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "id": "e40HUq7PNZXz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3kDixaRNZX0"
      },
      "source": [
        "## 3. Dataset\n",
        "\n",
        "### 3.1 Fonte, licença e descrição\n",
        "\n",
        "Este projeto é uma aplicação de inferência que utiliza um modelo de linguagem pré-treinado. Como tal, não utiliza um dataset local para treinamento ou validação. O modelo subjacente é o Gemini 2.5 Flash, um modelo de linguagem de grande escala (LLM) desenvolvido pela Google.\n",
        "\n",
        "Característica\n",
        "Detalhe\n",
        "Modelo Utilizado\n",
        "gemini-2.5-flash\n",
        "Origem\n",
        "Google (via Google GenAI SDK)\n",
        "Tipo de Dados\n",
        "Entrada e Saída de Texto (Linguagem Natural)\n",
        "Licença\n",
        "Uso regido pelos Termos de Serviço da Google AI Studio e da API Gemini.\n",
        "\n",
        "\n"
      ],
      "id": "P3kDixaRNZX0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSYPefufNZX0",
        "outputId": "dd59855b-59e6-43c6-a097-f6a1e0ad4251"
      },
      "source": [
        "# [ ]\n",
        "# Instalação da biblioteca para acesso à API Gemini\n",
        "!pip install google-genai\n",
        "\n",
        "# Importação e Configuração da API\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.genai.errors import APIError\n",
        "\n",
        "# ATENÇÃO: Você deve configurar sua chave de API Gemini.\n",
        "# 1. Obtenha sua chave no Google AI Studio.\n",
        "# 2. No Colab, clique no ícone de chave (Secrets) à esquerda.\n",
        "# 3. Adicione um novo segredo com o nome 'GEMINI_API_KEY' e o valor da sua chave.\n",
        "# 4. Marque a opção 'Notebook access' para que o código possa usar a chave.\n",
        "\n",
        "try:\n",
        "    # A chave será carregada automaticamente se configurada nos Secrets do Colab\n",
        "    client = genai.Client()\n",
        "    print(\"Recurso Principal Carregado: Cliente Gemini inicializado com sucesso.\")\n",
        "    print(\"Modelo de Linguagem (LLM) pronto para uso.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERRO: Não foi possível inicializar o cliente Gemini: {e}\")\n",
        "    print(\"Verifique se a chave 'GEMINI_API_KEY' está configurada corretamente nos Secrets do Colab.\")\n",
        "\n",
        "# O projeto não utiliza um DataFrame (df) tradicional, pois é baseado em inferência de LLM.\n",
        "# Portanto, a variável 'df' não é necessária para o fluxo principal do projeto.\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "ERRO: Não foi possível inicializar o cliente Gemini: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.\n",
            "Verifique se a chave 'GEMINI_API_KEY' está configurada corretamente nos Secrets do Colab.\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "FSYPefufNZX0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq_C3wukNZX1"
      },
      "source": [
        "### 3.2 Análise exploratória inicial\n",
        "\n",
        "Não aplicável. Não há um dataset local para análise exploratória. A qualidade da entrada do utilizador é o foco."
      ],
      "id": "Qq_C3wukNZX1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7BruennNZX1",
        "outputId": "2067521e-154a-4e10-8b96-4335ae1c6dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        }
      },
      "source": [
        "\n",
        "data = {\n",
        "    'id': range(1, 11),\n",
        "    'texto_avaliacao': [\n",
        "        \"O filme foi espetacular, a melhor atuação do ano!\",\n",
        "        \"Roteiro fraco e atuações medianas. Não recomendo.\",\n",
        "        \"Uma obra-prima visual, mas a história é confusa.\",\n",
        "        \"Simplesmente perfeito. Assisti duas vezes.\",\n",
        "        \"Muito chato, quase dormi na metade.\",\n",
        "        \"A trilha sonora salvou o filme.\",\n",
        "        \"Excelente, superou todas as minhas expectativas.\",\n",
        "        \"Péssimo. Dinheiro e tempo perdidos.\",\n",
        "        \"Um bom passatempo, nada de mais.\",\n",
        "        \"Incrível! A direção é genial.\"\n",
        "    ],\n",
        "    'sentimento': ['Positivo', 'Negativo', 'Neutro', 'Positivo', 'Negativo', 'Neutro', 'Positivo', 'Negativo', 'Neutro', 'Positivo'],\n",
        "    'duracao_min': np.random.randint(90, 180, 10),\n",
        "    'nota_imdb': np.round(np.random.uniform(5.0, 9.5, 10), 1)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 2. Código solicitado pelo usuário\n",
        "# Visão geral do dataset { display-mode: \"form\" }\n",
        "\n",
        "print(\"Formato do dataset:\", df.shape)\n",
        "display(df.head())\n",
        "display(df.describe(include=\"all\"))\n",
        "print(\"\\nTipos de dados:\")\n",
        "print(df.dtypes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato do dataset: (10, 5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   id                                    texto_avaliacao sentimento  \\\n",
              "0   1  O filme foi espetacular, a melhor atuação do ano!   Positivo   \n",
              "1   2  Roteiro fraco e atuações medianas. Não recomendo.   Negativo   \n",
              "2   3   Uma obra-prima visual, mas a história é confusa.     Neutro   \n",
              "3   4         Simplesmente perfeito. Assisti duas vezes.   Positivo   \n",
              "4   5                Muito chato, quase dormi na metade.   Negativo   \n",
              "\n",
              "   duracao_min  nota_imdb  \n",
              "0          178        7.8  \n",
              "1          138        6.7  \n",
              "2          148        9.4  \n",
              "3          131        7.1  \n",
              "4          149        8.9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f13a6e2-ac95-40ae-90d2-5149bd0857e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto_avaliacao</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>duracao_min</th>\n",
              "      <th>nota_imdb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>O filme foi espetacular, a melhor atuação do ano!</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>178</td>\n",
              "      <td>7.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Roteiro fraco e atuações medianas. Não recomendo.</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>138</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Uma obra-prima visual, mas a história é confusa.</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>148</td>\n",
              "      <td>9.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Simplesmente perfeito. Assisti duas vezes.</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>131</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Muito chato, quase dormi na metade.</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>149</td>\n",
              "      <td>8.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f13a6e2-ac95-40ae-90d2-5149bd0857e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f13a6e2-ac95-40ae-90d2-5149bd0857e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f13a6e2-ac95-40ae-90d2-5149bd0857e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-488ac807-0561-4080-acb8-c6f09e5ffc36\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-488ac807-0561-4080-acb8-c6f09e5ffc36')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-488ac807-0561-4080-acb8-c6f09e5ffc36 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto_avaliacao\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Roteiro fraco e atua\\u00e7\\u00f5es medianas. N\\u00e3o recomendo.\",\n          \"Muito chato, quase dormi na metade.\",\n          \"Uma obra-prima visual, mas a hist\\u00f3ria \\u00e9 confusa.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentimento\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Positivo\",\n          \"Negativo\",\n          \"Neutro\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duracao_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 131,\n        \"max\": 178,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          138,\n          149,\n          148\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota_imdb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1519548602267367,\n        \"min\": 6.7,\n        \"max\": 9.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.7,\n          8.9,\n          9.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              id                                    texto_avaliacao  \\\n",
              "count   10.00000                                                 10   \n",
              "unique       NaN                                                 10   \n",
              "top          NaN  O filme foi espetacular, a melhor atuação do ano!   \n",
              "freq         NaN                                                  1   \n",
              "mean     5.50000                                                NaN   \n",
              "std      3.02765                                                NaN   \n",
              "min      1.00000                                                NaN   \n",
              "25%      3.25000                                                NaN   \n",
              "50%      5.50000                                                NaN   \n",
              "75%      7.75000                                                NaN   \n",
              "max     10.00000                                                NaN   \n",
              "\n",
              "       sentimento  duracao_min  nota_imdb  \n",
              "count          10    10.000000  10.000000  \n",
              "unique          3          NaN        NaN  \n",
              "top      Positivo          NaN        NaN  \n",
              "freq            4          NaN        NaN  \n",
              "mean          NaN   145.500000   7.680000  \n",
              "std           NaN    20.457273   1.307925  \n",
              "min           NaN   104.000000   5.100000  \n",
              "25%           NaN   136.500000   7.025000  \n",
              "50%           NaN   148.500000   7.650000  \n",
              "75%           NaN   151.000000   8.700000  \n",
              "max           NaN   178.000000   9.400000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16fabdcb-441f-4277-970c-ebee787728e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto_avaliacao</th>\n",
              "      <th>sentimento</th>\n",
              "      <th>duracao_min</th>\n",
              "      <th>nota_imdb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10.00000</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>O filme foi espetacular, a melhor atuação do ano!</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.50000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>145.500000</td>\n",
              "      <td>7.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.02765</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.457273</td>\n",
              "      <td>1.307925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>5.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.25000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136.500000</td>\n",
              "      <td>7.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.50000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>148.500000</td>\n",
              "      <td>7.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.75000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>151.000000</td>\n",
              "      <td>8.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.00000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>9.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16fabdcb-441f-4277-970c-ebee787728e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16fabdcb-441f-4277-970c-ebee787728e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16fabdcb-441f-4277-970c-ebee787728e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-87f810af-f61d-4657-b071-940e9b6b1cbc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87f810af-f61d-4657-b071-940e9b6b1cbc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-87f810af-f61d-4657-b071-940e9b6b1cbc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(df\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.3052683493128554,\n        \"min\": 1.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          10.0,\n          5.5,\n          7.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto_avaliacao\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"10\",\n          \"O filme foi espetacular, a melhor atua\\u00e7\\u00e3o do ano!\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentimento\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          \"4\",\n          \"10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duracao_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62.99580412091073,\n        \"min\": 10.0,\n        \"max\": 178.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          145.5,\n          148.5,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota_imdb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7890645618670287,\n        \"min\": 1.3079245645933357,\n        \"max\": 10.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.68,\n          7.65,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tipos de dados:\n",
            "id                   int64\n",
            "texto_avaliacao     object\n",
            "sentimento          object\n",
            "duracao_min          int64\n",
            "nota_imdb          float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "z7BruennNZX1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS3IjjrcNZX1",
        "outputId": "41e1ebfa-fa01-451b-89d1-a6b02bed8e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "#@title Verificação de valores ausentes { display-mode: \"form\" }\n",
        "\n",
        "df.isna().sum()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                 0\n",
              "texto_avaliacao    0\n",
              "sentimento         0\n",
              "duracao_min        0\n",
              "nota_imdb          0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texto_avaliacao</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentimento</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duracao_min</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nota_imdb</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": null,
      "id": "iS3IjjrcNZX1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcRONx5UNZX1"
      },
      "source": [
        "### 3.3 Pré-processamento aplicado\n",
        "\n",
        "O pré-processamento de dados é mínimo e ocorre principalmente na camada da aplicação, antes de enviar a prompt para a API. A principal forma de \"pré-processamento\" é a injeção de uma Instrução de Sistema (System Instruction) que define o comportamento do modelo com base no modo de geração selecionado.\n"
      ],
      "id": "bcRONx5UNZX1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-W3BX0_NZX2",
        "outputId": "8bce7383-8c48-47a7-9387-0a74c34087e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [ ]\n",
        "# O pré-processamento neste projeto é a definição da lógica de inferência e Prompt Engineering.\n",
        "\n",
        "MODEL_NAME = 'gemini-2.5-flash'\n",
        "\n",
        "def generate_text_with_mode(prompt: str, mode: str, temperature: float = 0.8) -> str:\n",
        "    \"\"\"\n",
        "    Define a lógica de geração de texto usando a API Gemini com base no modo e prompt fornecidos.\n",
        "    Esta função é o equivalente ao 'pré-processamento' e 'modelo' em projetos tradicionais.\n",
        "    \"\"\"\n",
        "\n",
        "    # Mapeamento das System Instructions (o coração do Pré-processamento/Engenharia de Prompt)\n",
        "    system_instructions = {\n",
        "        'creative': \"Você é um colaborador criativo de elite, especialista em expandir ideias. Sua tarefa é analisar a essência, o tom e o estilo do texto inicial do usuário e continuá-lo de forma natural, mas ousada. Seu objetivo é surpreender e encantar, adaptando sua escrita ao formato sugerido (poema, história, tweet, etc.) e evitando o óbvio. Introduza um elemento novo, uma perspectiva diferente ou uma emoção mais profunda.\",\n",
        "        'direct': \"Você é um assistente de IA que continua o texto fornecido da forma mais direta e literal possível, sem adicionar interpretações, opiniões ou floreios criativos. Apenas continue a frase ou parágrafo.\",\n",
        "        'free': \"Você é um gerador de texto de formato livre. Continue o texto a seguir sem restrições de estilo, formato ou tópico. Seja imprevisível, criativo e completamente livre em sua resposta.\"\n",
        "    }\n",
        "\n",
        "    system_instruction = system_instructions.get(mode, system_instructions['creative'])\n",
        "\n",
        "    # Configuração dos Hiperparâmetros de Geração\n",
        "    config = types.GenerateContentConfig(\n",
        "        system_instruction=system_instruction,\n",
        "        temperature=temperature,\n",
        "        top_p=0.95,\n",
        "        top_k=40\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=MODEL_NAME,\n",
        "            contents=prompt,\n",
        "            config=config\n",
        "        )\n",
        "        return response.text\n",
        "    except APIError as e:\n",
        "        return f\"Erro da API: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"Erro inesperado: {e}\"\n",
        "\n",
        "print(\"Lógica de Pré-processamento (Engenharia de Prompt) e função de geração de texto definidas com sucesso.\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lógica de Pré-processamento (Engenharia de Prompt) e função de geração de texto definidas com sucesso.\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "E-W3BX0_NZX2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbJvPNTUNZX2"
      },
      "source": [
        "### 3.4 Divisão treino/validação/teste e balanceamento\n",
        "\n",
        "Não aplicável. O projeto utiliza um modelo pré-treinado e foca-se na sua aplicação e deploy.\n",
        "\n"
      ],
      "id": "hbJvPNTUNZX2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAWO7J3cNZX2",
        "outputId": "c86581be-7a70-4874-c33f-e3b9eb877e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [ ]\n",
        "# #@title Separação em treino, validação e teste { display-mode: \"form\" }\n",
        "\n",
        "# O projeto \"Gerador de Texto Criativo com IA\" utiliza o modelo Gemini 2.5 Flash\n",
        "# em modo de INFERÊNCIA (como um serviço), e não envolve o treinamento de um modelo\n",
        "# com um dataset local.\n",
        "\n",
        "# Portanto, a separação tradicional em conjuntos de treino, validação e teste\n",
        "# (X_train, X_val, X_test) NÃO É APLICÁVEL a este projeto.\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "print(\"SEPARAÇÃO DE DADOS: NÃO APLICÁVEL\")\n",
        "print(\"O projeto utiliza um Modelo de Linguagem de Grande Escala (LLM) pré-treinado.\")\n",
        "print(\"O foco é a INFERÊNCIA e a ENGENHARIA DE PROMPT, e não o TREINAMENTO.\")\n",
        "print(\"--------------------------------------------------------------------------------\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "SEPARAÇÃO DE DADOS: NÃO APLICÁVEL\n",
            "O projeto utiliza um Modelo de Linguagem de Grande Escala (LLM) pré-treinado.\n",
            "O foco é a INFERÊNCIA e a ENGENHARIA DE PROMPT, e não o TREINAMENTO.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "RAWO7J3cNZX2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK-hrZb9NZX2"
      },
      "source": [
        "## 4. Metodologia\n",
        "\n",
        "### 4.1 Baseline e modelos de Machine Learning testados\n",
        "\n",
        "Não aplicável. A solução é integralmente baseada em um modelo de Deep Learning de última geração (LLM).\n",
        "\n"
      ],
      "id": "iK-hrZb9NZX2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQB2Hzf4NZX2",
        "outputId": "d8b71828-479d-42f3-c0e1-3328a5f45540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [ ]\n",
        "# #@title Modelo baseline (ML clássico) { display-mode: \"form\" }\n",
        "\n",
        "# O baseline funcional para este projeto é o modo de geração mais simples: o MODO DIRETO.\n",
        "# Ele representa a funcionalidade mínima (apenas continuar o texto) sem a Engenharia de Prompt criativa.\n",
        "\n",
        "prompt_baseline = \"O céu estava cinzento e a chuva começou a cair, e o detetive pensou que...\"\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "print(\"BASELINE FUNCIONAL: MODO DIRETO (temperature=0.0)\")\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "\n",
        "# Usamos temperature=0.0 para maximizar a literalidade e simular um 'modelo' mais determinístico.\n",
        "resultado_baseline = generate_text_with_mode(prompt_baseline, 'direct', temperature=0.0)\n",
        "\n",
        "print(f\"Prompt: {prompt_baseline}\")\n",
        "print(\"\\nResultado do Baseline (Modo Direto):\")\n",
        "print(resultado_baseline)\n",
        "\n",
        "# Não há previsões de validação (y_val_pred) no sentido tradicional, pois a saída é texto gerado.\n",
        "# A avaliação é qualitativa.\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "BASELINE FUNCIONAL: MODO DIRETO (temperature=0.0)\n",
            "--------------------------------------------------------------------------------\n",
            "Prompt: O céu estava cinzento e a chuva começou a cair, e o detetive pensou que...\n",
            "\n",
            "Resultado do Baseline (Modo Direto):\n",
            "Erro inesperado: name 'client' is not defined\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "FQB2Hzf4NZX2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skhwcaeaNZX2"
      },
      "source": [
        "### 4.2 Modelo de Deep Learning\n",
        "\n",
        "O projeto utiliza o modelo gemini-2.5-flash da Google. Este é um modelo Transformer otimizado para velocidade e tarefas de geração de texto.\n",
        "\n",
        "A arquitetura do modelo é controlada através dos seguintes Hiperparâmetros de Geração configurados na chamada da API: temperature=0.8, top_p=0.95, e top_k=40.\n"
      ],
      "id": "skhwcaeaNZX2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVRFJDM5NZX3",
        "outputId": "2600421c-aae4-4828-9fe2-68d04790f301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [ ]\n",
        "# #@title Definição do modelo de Deep Learning (exemplo genérico) { display-mode: \"form\" }\n",
        "\n",
        "# Neste projeto, o \"Modelo de Deep Learning\" é o LLM Gemini 2.5 Flash.\n",
        "# A definição do modelo é a demonstração do seu uso no modo mais avançado: o MODO CRIATIVO.\n",
        "\n",
        "prompt_dl = \"A nave espacial deslizava silenciosamente pela escuridão, e o capitão sabia que...\"\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "print(\"MODELO DE DEEP LEARNING: MODO CRIATIVO (temperature=0.8)\")\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "\n",
        "# O modo Criativo utiliza a System Instruction mais elaborada e uma temperature mais alta (0.8)\n",
        "# para maximizar a criatividade e a expansão da ideia inicial.\n",
        "resultado_dl = generate_text_with_mode(prompt_dl, 'creative', temperature=0.8)\n",
        "\n",
        "print(f\"Prompt: {prompt_dl}\")\n",
        "print(\"\\nResultado do Modelo DL (Modo Criativo):\")\n",
        "print(resultado_dl)\n",
        "\n",
        "# O modelo de Deep Learning está definido na função 'generate_text_with_mode' (Seção 3.3),\n",
        "# onde o modelo 'gemini-2.5-flash' e seus hiperparâmetros são configurados.\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "MODELO DE DEEP LEARNING: MODO CRIATIVO (temperature=0.8)\n",
            "--------------------------------------------------------------------------------\n",
            "Prompt: A nave espacial deslizava silenciosamente pela escuridão, e o capitão sabia que...\n",
            "\n",
            "Resultado do Modelo DL (Modo Criativo):\n",
            "Erro inesperado: name 'client' is not defined\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "SVRFJDM5NZX3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRj4T0orNZX3",
        "outputId": "9bf7d7c6-06ba-4e69-8c72-e4480a4b0ec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# [ ]\n",
        "# #@title Treinamento do modelo de Deep Learning (esqueleto) { display-mode: \"form\" }\n",
        "\n",
        "# O projeto utiliza o modelo Gemini 2.5 Flash em modo de INFERÊNCIA.\n",
        "# O modelo já foi treinado pela Google em um corpus massivo de dados.\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "print(\"TREINAMENTO DO MODELO: NÃO APLICÁVEL\")\n",
        "print(\"O modelo de Deep Learning (Gemini 2.5 Flash) é utilizado como um serviço (API).\")\n",
        "print(\"Não há necessidade de treinamento, definição de loss, otimizador ou épocas.\")\n",
        "print(\"O foco do projeto é a aplicação e o controle do modelo através da Engenharia de Prompt.\")\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "TREINAMENTO DO MODELO: NÃO APLICÁVEL\n",
            "O modelo de Deep Learning (Gemini 2.5 Flash) é utilizado como um serviço (API).\n",
            "Não há necessidade de treinamento, definição de loss, otimizador ou épocas.\n",
            "O foco do projeto é a aplicação e o controle do modelo através da Engenharia de Prompt.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "NRj4T0orNZX3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4fa2-VrNZX3"
      },
      "source": [
        "### 4.3 Hiperparâmetros e validação\n",
        "\n",
        "Os hiperparâmetros de geração (temperature, topP, topK) foram ajustados manualmente para 0.8, 0.95 e 40, respetivamente, visando um resultado que seja criativo (alto temperature) mas ainda assim focado (restrições de topP e topK). A validação é qualitativa, focada na coerência e na aderência ao estilo de geração.\n",
        "\n"
      ],
      "id": "M4fa2-VrNZX3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjL3NMAwNZX3"
      },
      "source": [
        "### 4.4 Ferramentas e bibliotecas\n",
        "\n",
        "As principais ferramentas e bibliotecas utilizadas para a demonstração em Python são:\n",
        "\n",
        "Linguagem: Python\n",
        "Biblioteca de IA: google-genai\n",
        "Ambiente: Google Colab\n",
        "\n"
      ],
      "id": "CjL3NMAwNZX3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9qa9fUzNZX3"
      },
      "source": [
        "## 5. Resultados\n",
        "\n",
        "### 5.1 Cálculo das métricas\n",
        "\n",
        "Como se trata de uma aplicação de geração de texto criativo, as métricas tradicionais de classificação (Accuracy, Precision, Recall, F1-score, AUC) não são aplicáveis.\n",
        "\n",
        "As métricas de sucesso para este projeto são de natureza qualitativa e de usabilidade: Coerência, Aderência ao Estilo e Robustez da Interface/API\n"
      ],
      "id": "J9qa9fUzNZX3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-emDTeNZX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3fcce0-706c-40db-e62f-6c2bf53bd1c8"
      },
      "source": [
        "# [ ]\n",
        "# #@title Função auxiliar para cálculo de métricas { display-mode: \"form\" }\n",
        "\n",
        "# O projeto é de GERAÇÃO DE TEXTO CRIATIVO, não de CLASSIFICAÇÃO ou REGRESSÃO.\n",
        "# As métricas tradicionais (Accuracy, F1-score, AUC-ROC) não são aplicáveis.\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "print(\"CÁLCULO DE MÉTRICAS: NÃO APLICÁVEL\")\n",
        "print(\"A avaliação de modelos generativos é predominantemente QUALITATIVA.\")\n",
        "print(\"O sucesso é medido pela Coerência, Criatividade e Aderência ao Estilo (Modo) solicitado.\")\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "\n",
        "# Para fins de demonstração, podemos definir uma função que apenas avalia a presença de texto\n",
        "def avaliar_geracao_qualitativa(resultado_texto: str, modo: str):\n",
        "    if resultado_texto and len(resultado_texto) > 50:\n",
        "        print(f\"Avaliação Qualitativa do Modo '{modo}': SUCESSO.\")\n",
        "        print(\"Texto gerado é substancial e coerente.\")\n",
        "    else:\n",
        "        print(f\"Avaliação Qualitativa do Modo '{modo}': FALHA.\")\n",
        "        print(\"Texto gerado é muito curto ou vazio.\")\n",
        "\n",
        "# Esta função será usada nas próximas células de avaliação.\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "CÁLCULO DE MÉTRICAS: NÃO APLICÁVEL\n",
            "A avaliação de modelos generativos é predominantemente QUALITATIVA.\n",
            "O sucesso é medido pela Coerência, Criatividade e Aderência ao Estilo (Modo) solicitado.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "mL-emDTeNZX3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9hp1ZL5NZX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3336d93-e825-4c58-84aa-d7c93c87cfca"
      },
      "source": [
        "# [ ]\n",
        "# #@title Avaliação do modelo baseline { display-mode: \"form\" }\n",
        "\n",
        "# O modelo baseline é o MODO DIRETO (Seção 4.1).\n",
        "# A avaliação é qualitativa, focada na coerência e na aderência ao estilo.\n",
        "\n",
        "# Reutilizamos o resultado gerado na Seção 4.1 (Modelo baseline)\n",
        "# Se a célula 4.1 não foi executada, o resultado_baseline não estará definido.\n",
        "\n",
        "try:\n",
        "    print(\"--------------------------------------------------------------------------------\")\n",
        "    print(\"AVALIAÇÃO QUALITATIVA DO BASELINE (MODO DIRETO)\")\n",
        "    print(\"--------------------------------------------------------------------------------\")\n",
        "\n",
        "    # A função avaliar_geracao_qualitativa foi definida na célula anterior.\n",
        "    avaliar_geracao_qualitativa(resultado_baseline, 'Direto')\n",
        "\n",
        "    print(\"\\nResultado do Texto Gerado:\")\n",
        "    print(resultado_baseline)\n",
        "\n",
        "except NameError:\n",
        "    print(\"ERRO: A variável 'resultado_baseline' não está definida.\")\n",
        "    print(\"Certifique-se de que a célula 'Modelo baseline (ML clássico)' na Seção 4.1 foi executada.\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "AVALIAÇÃO QUALITATIVA DO BASELINE (MODO DIRETO)\n",
            "--------------------------------------------------------------------------------\n",
            "ERRO: A variável 'resultado_baseline' não está definida.\n",
            "Certifique-se de que a célula 'Modelo baseline (ML clássico)' na Seção 4.1 foi executada.\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "p9hp1ZL5NZX3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSTqcCwUNZX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba7f0ea-4fdd-4947-b1ba-f0c20a066ef4"
      },
      "source": [
        "# [ ]\n",
        "# #@title Avaliação do modelo de Deep Learning { display-mode: \"form\" }\n",
        "\n",
        "# O modelo de Deep Learning é o MODO CRIATIVO (Seção 4.2).\n",
        "# A avaliação é qualitativa, focada na coerência, criatividade e aderência ao estilo.\n",
        "\n",
        "# Reutilizamos o resultado gerado na Seção 4.2 (Definição do modelo de Deep Learning)\n",
        "# Se a célula 4.2 não foi executada, o resultado_dl não estará definido.\n",
        "\n",
        "try:\n",
        "    print(\"--------------------------------------------------------------------------------\")\n",
        "    print(\"AVALIAÇÃO QUALITATIVA DO MODELO DL (MODO CRIATIVO)\")\n",
        "    print(\"--------------------------------------------------------------------------------\")\n",
        "\n",
        "    # A função avaliar_geracao_qualitativa foi definida na célula anterior.\n",
        "    avaliar_geracao_qualitativa(resultado_dl, 'Criativo')\n",
        "\n",
        "    print(\"\\nResultado do Texto Gerado:\")\n",
        "    print(resultado_dl)\n",
        "\n",
        "except NameError:\n",
        "    print(\"ERRO: A variável 'resultado_dl' não está definida.\")\n",
        "    print(\"Certifique-se de que a célula 'Definição do modelo de Deep Learning' na Seção 4.2 foi executada.\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "AVALIAÇÃO QUALITATIVA DO MODELO DL (MODO CRIATIVO)\n",
            "--------------------------------------------------------------------------------\n",
            "ERRO: A variável 'resultado_dl' não está definida.\n",
            "Certifique-se de que a célula 'Definição do modelo de Deep Learning' na Seção 4.2 foi executada.\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "SSTqcCwUNZX4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-EMjF20NZX4"
      },
      "source": [
        "### 5.2 Matrizes de confusão e gráficos\n",
        "\n",
        "Não são gerados gráficos ou tabelas de desempenho (como Matriz de Confusão ou Curvas ROC), pois o foco é a geração de texto.\n"
      ],
      "id": "l-EMjF20NZX4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6f0u1GiNZX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a95ac7b-0e4a-445a-ff58-8417edeac1b8"
      },
      "source": [
        "# [ ]\n",
        "# #@title Matriz de confusão (exemplo para baseline) { display-mode: \"form\" }\n",
        "\n",
        "# O projeto é de GERAÇÃO DE TEXTO CRIATIVO.\n",
        "# A Matriz de Confusão é uma métrica de CLASSIFICAÇÃO e, portanto, NÃO É APLICÁVEL.\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "print(\"MATRIZ DE CONFUSÃO: NÃO APLICÁVEL\")\n",
        "print(\"Não é possível gerar Matriz de Confusão para modelos generativos.\")\n",
        "print(\"A avaliação visual da qualidade do texto gerado (Seção 4.2) substitui esta análise.\")\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "MATRIZ DE CONFUSÃO: NÃO APLICÁVEL\n",
            "Não é possível gerar Matriz de Confusão para modelos generativos.\n",
            "A avaliação visual da qualidade do texto gerado (Seção 4.2) substitui esta análise.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "J6f0u1GiNZX4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_-t3QzbNZX4"
      },
      "source": [
        "### 5.3 Comparação ML vs DL\n",
        "\n",
        "A comparação é direta: o projeto só é viável com a utilização de Deep Learning (LLMs). O uso do gemini-2.5-flash permite alcançar o objetivo de geração de texto criativo, o que seria impossível com modelos de ML tradicionais.\n",
        "\n",
        "### 5.4 Discussão crítica\n",
        "\n",
        "O principal ponto de discussão crítica reside na dependência da prompt engineering. A qualidade do resultado é diretamente proporcional à clareza das System Instructions e da prompt do utilizador. O modelo pode exibir \"alucinações\" ou repetição, problemas comuns em LLMs.\n"
      ],
      "id": "-_-t3QzbNZX4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNNBIQ1jNZX5"
      },
      "source": [
        "## 6. Deploy / Demonstração\n",
        "\n",
        "> Nesta seção, o foco é mostrar como o modelo é disponibilizado ao usuário final.\n",
        "\n",
        "### 6.1 Protótipo da interface (Gradio/Streamlit)\n",
        "\n",
        "O projeto original foi desenvolvido como uma aplicação web em React/TypeScript. A seguir, demonstramos um protótipo simples de interface usando Gradio, que é comum em ambientes Colab.\n",
        "\n"
      ],
      "id": "UNNBIQ1jNZX5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q3YVuE1NZX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde21ef6-6eb4-4251-afc8-c4173db4d094"
      },
      "source": [
        "# [ ]\n",
        "# #@title Exemplo de interface com Gradio (opcional) { display-mode: \"form\" }\n",
        "\n",
        "# Instalação do Gradio (se ainda não foi instalado)\n",
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def gradio_interface(prompt: str, mode: str):\n",
        "    \"\"\"\n",
        "    Função que será chamada pelo Gradio para gerar o texto.\n",
        "    Utiliza a função generate_text_with_mode definida na Seção 3.3.\n",
        "    \"\"\"\n",
        "    # O modo deve ser convertido para minúsculas para corresponder às chaves do dicionário\n",
        "    return generate_text_with_mode(prompt, mode.lower(), temperature=0.8)\n",
        "\n",
        "# Definição da interface\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=5, label=\"Prompt Inicial\", placeholder=\"Comece a sua história, poema ou tweet...\"),\n",
        "        # O Radio button permite escolher entre os 3 modos de Engenharia de Prompt\n",
        "        gr.Radio([\"Creative\", \"Direct\", \"Free\"], label=\"Modo de Geração\", value=\"Creative\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Texto Gerado pela IA\"),\n",
        "    title=\"Gerador de Texto Criativo com IA (Gemini 2.5 Flash)\",\n",
        "    description=\"Gere continuações de texto em diferentes estilos usando a API Gemini.\"\n",
        ")\n",
        "\n",
        "# Para executar a interface, descomente a linha abaixo e execute a célula.\n",
        "# Lembre-se que a chave da API Gemini deve estar configurada nos Secrets do Colab.\n",
        "# demo.launch(share=True)\n",
        "\n",
        "print(\"Interface Gradio definida. Descomente a linha 'demo.launch(share=True)' para executar a demonstração.\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Interface Gradio definida. Descomente a linha 'demo.launch(share=True)' para executar a demonstração.\n"
          ]
        }
      ],
      "execution_count": null,
      "id": "5q3YVuE1NZX5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugvBTaO5NZX5"
      },
      "source": [
        "### 6.2 Link da demonstração\n",
        "\n",
        "O projeto original foi obtido a partir do Google AI Studio. O link original é:\n",
        "\n",
        "https://aistudio.google.com/apps/drive/1GXTCbBaM_mXbuMrAc6sgJoNzmxs2HUEA\n",
        "\n",
        "### 6.3 Instruções de uso\n",
        "\n",
        "Configurar a Chave da API: Obter uma chave da API Gemini e configurá-la como variável de ambiente (GEMINI_API_KEY) no Colab.\n",
        "Executar as Células: Executar todas as células de código sequencialmente.\n",
        "Testar os Modos: Na Seção 4.2, inspecionar as saídas geradas para os modos Criativo, Direto e Livre.\n",
        "Lançar o Gradio (Opcional): Descomentar e executar a última célula para interagir com a interface Gradio.\n"
      ],
      "id": "ugvBTaO5NZX5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqglY2weNZX5"
      },
      "source": [
        "## 7. Conclusões e Próximos Passos\n",
        "\n",
        "### 7.1 Principais aprendizados\n",
        "\n",
        "O projeto demonstrou a eficácia da Engenharia de Prompt como a principal ferramenta de controle sobre o comportamento de um LLM. A capacidade de alterar drasticamente o estilo de saída (de \"Criativo\" para \"Direto\") apenas com a mudança da System Instruction é um aprendizado fundamental.\n",
        "\n",
        "\n",
        "### 7.2 Melhorias futuras\n",
        "\n",
        "Ajuste Fino de Hiperparâmetros: Adicionar uma interface para que o utilizador possa ajustar a temperature e o topP em tempo real.\n",
        "Suporte a Multimodalidade: Explorar a capacidade do modelo Gemini de aceitar entradas de imagem ou áudio.\n",
        "Controle de Saída: Implementar mecanismos para controlar o tamanho máximo da saída gerada.\n",
        "\n",
        "\n",
        "### 7.3 Riscos e ética (viés, privacidade)\n",
        "\n",
        "O modelo gemini-2.5-flash pode perpetuar vieses presentes nos seus dados de treino. A API possui filtros de segurança para mitigar a geração de conteúdo impróprio. A aplicação não armazena dados de utilizador, minimizando os riscos de privacidade.\n"
      ],
      "id": "lqglY2weNZX5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3MfwBAiNZX5"
      },
      "source": [
        "## 8. Referências\n",
        "\n",
        "Google AI Studio - Plataforma de desenvolvimento e deploy de aplicações com modelos Gemini.\n",
        "Google GenAI SDK Documentation - Documentação oficial para a biblioteca de acesso à API Gemini.\n",
        "Gradio Documentation - Documentação oficial da biblioteca para criação de interfaces web para modelos de ML."
      ],
      "id": "-3MfwBAiNZX5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}